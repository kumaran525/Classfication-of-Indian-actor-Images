{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d4f0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import glob\n",
    "from ipynb.fs.full.utils import CLASS_NAMES, makedirs\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91eee6",
   "metadata": {},
   "source": [
    "<h2>Applying resize and Contrast-limited adaptive histogram equalization to Preprocess the image for normalizing pixel intensities</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c942656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img_p, size=(640, 480)):\n",
    "    img = cv2.imread(img_p)\n",
    "    return cv2.resize(img, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b39248e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(img):\n",
    "    return cv2.medianBlur(img, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91640519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    lab_planes = list(cv2.split(lab))\n",
    "    clahe_ = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(5, 5))\n",
    "    lab_planes[0] = clahe_.apply(lab_planes[0])\n",
    "    lab = cv2.merge(tuple(lab_planes))\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9eb9b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_p, ret=False):\n",
    "    img = resize(img_p,size=(1000,1000))\n",
    "    median_filtered = median_filter(img)\n",
    "    clahe_applied = clahe(median_filtered)\n",
    "    if ret:\n",
    "        return {'Median Filtered': median_filtered, 'Contrast Enhanced': clahe_applied}\n",
    "    return clahe_applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "668a614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: nagarjuna_akkineni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 70.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: madhavan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 67.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: kamal_haasan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 74.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: saif_ali_khan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: mohanlal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 75.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: prabhas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 72.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: sanjay_dutt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 73.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: akshay_kumar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 71.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: ramya_krishnan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 70.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing For Class :: salman_khan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 69.95it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"Picked_data/\"\n",
    "output_dir = \"ProcessedData\"\n",
    "\n",
    "# Iterate through each class folder\n",
    "for class_folder in os.listdir(input_dir):\n",
    "    class_path = os.path.join(input_dir, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    \n",
    "    output_class_path = os.path.join(output_dir, class_folder)\n",
    "    os.makedirs(output_class_path, exist_ok=True)\n",
    "    \n",
    "    # Iterate through each image file in the class folder\n",
    "    print('[INFO] Preprocessing For Class :: {0}'.format(class_folder))\n",
    "    for image_file in tqdm.tqdm(os.listdir(class_path)):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        \n",
    "        padded_image = preprocess(image_path)\n",
    "        # Save the cropped/padded image to the output directory\n",
    "        output_image_path = os.path.join(output_class_path, image_file)\n",
    "        cv2.imwrite(output_image_path, padded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44465b",
   "metadata": {},
   "source": [
    "<h2>Splitting the Processed data into train and test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d2d2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to your image data directory\n",
    "data_dir = \"ProcessedData/\"\n",
    "\n",
    "# Set the directory names for train and test sets\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Get the list of class directories\n",
    "class_dirs = os.listdir(data_dir)\n",
    "\n",
    "# Iterate over each class directory\n",
    "for class_dir in class_dirs:\n",
    "    class_path = os.path.join(data_dir, class_dir)\n",
    "    \n",
    "    #break\n",
    "    # Get the list of image files in the class directory\n",
    "    image_files = os.listdir(class_path)\n",
    "    if class_path not in 'ProcessedData/.ipynb_checkpoints':\n",
    "    #print(image_files)\n",
    "    \n",
    "        # Perform the train-test split while maintaining class distribution\n",
    "        train_files, test_files = train_test_split(image_files, test_size=0.1, random_state=42)\n",
    "\n",
    "        # Create class directories in train and test sets\n",
    "        train_class_dir = os.path.join(train_dir, class_dir)\n",
    "        test_class_dir = os.path.join(test_dir, class_dir)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "        #print(train_class_dir)\n",
    "\n",
    "        # Move the images to the corresponding train and test class directories\n",
    "        for file in train_files:\n",
    "            src = os.path.join(class_path, file)\n",
    "            dst = os.path.join(train_class_dir, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        for file in test_files:\n",
    "            src = os.path.join(class_path, file)\n",
    "            dst = os.path.join(test_class_dir, file)\n",
    "            shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(image_path, target_size=(1000,1000)):\n",
    "#     # Load the image\n",
    "#     image = cv2.imread(image_path)\n",
    "    \n",
    "#     # Calculate the aspect ratio\n",
    "#     height, width, _ = image.shape\n",
    "#     aspect_ratio = width / height\n",
    "    \n",
    "#     # Perform cropping or padding based on aspect ratio\n",
    "#     if aspect_ratio > target_size[0] / target_size[1]:\n",
    "#         new_width = int(height * (target_size[0] / target_size[1]))\n",
    "#         resized_image = cv2.resize(image, (new_width, target_size[1]))\n",
    "#         padding = max((target_size[0] - new_width) // 2, 0)\n",
    "#         padded_image = cv2.copyMakeBorder(resized_image, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "#     else:\n",
    "#         new_height = int(width * (target_size[1] / target_size[0]))\n",
    "#         resized_image = cv2.resize(image, (target_size[0], new_height))\n",
    "#         padding = max((target_size[1] - new_height) // 2, 0)\n",
    "#         padded_image = cv2.copyMakeBorder(resized_image, padding, padding, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    \n",
    "#     return padded_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
